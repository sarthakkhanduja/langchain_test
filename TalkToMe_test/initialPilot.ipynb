{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "folder_path = r\"C:\\Users\\LEGION\\Dropbox\\My PC (LAPTOP-E7LP1HPD)\\Desktop\\Windsor\\Thesis\\S - 2023\\MDS intro papers\"\n",
    "os.path.exists(folder_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_list = os.listdir(folder_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sk-proj-gD0Nxd5jJ5TKT3k2c2eET3BlbkFJKJzvqt3TQjt78eU4f05Z\n"
     ]
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = os.getenv(\"OPENAI_API_KEY\")\n",
    "print(os.environ[\"OPENAI_API_KEY\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_community.embeddings import OpenAIEmbeddings\n",
    "from langchain_community.vectorstores import Chroma\n",
    "\n",
    "embeddings = OpenAIEmbeddings()\n",
    "vectorstore = Chroma(embedding_function=embeddings)\n",
    "\n",
    "for file in file_list:\n",
    "    new_path = os.path.join(folder_path, file)\n",
    "    loader = PyPDFLoader(new_path)\n",
    "    docs = loader.load()\n",
    "\n",
    "    text_splitter = RecursiveCharacterTextSplitter(chunk_size = 500, chunk_overlap = 100)\n",
    "    documents = text_splitter.split_documents(docs)\n",
    "\n",
    "    vectorstore.add_documents(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OpenAI(client=<openai.resources.completions.Completions object at 0x00000219172CAD70>, async_client=<openai.resources.completions.AsyncCompletions object at 0x000002191502B880>, openai_api_key='sk-proj-gD0Nxd5jJ5TKT3k2c2eET3BlbkFJKJzvqt3TQjt78eU4f05Z', openai_proxy='')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_community.llms import OpenAI\n",
    "# from langchain_community.llms import Ollama\n",
    "\n",
    "llm = OpenAI(model=\"gpt-3.5-turbo-instruct\")\n",
    "# llm = Ollama(model=\"llama2\")\n",
    "llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "prompt = ChatPromptTemplate.from_template(\"\"\"\n",
    "                                          You are my Research Assistant. You will be given context via embeddings regarding a lot of research papers in my vector database.\n",
    "                                          Answer the following question based only on the provided context. \n",
    "                                          Think step by step before providing a detailed answer.\n",
    "                                          <context>\n",
    "                                          {context}\n",
    "                                          </context>\n",
    "                                          Question: {input}\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "document_chain = create_stuff_documents_chain(llm, prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VectorStoreRetriever(tags=['Chroma', 'OpenAIEmbeddings'], vectorstore=<langchain_community.vectorstores.chroma.Chroma object at 0x0000021916BCBBB0>)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retriever = vectorstore.as_retriever()\n",
    "retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import create_retrieval_chain\n",
    "\n",
    "retreival_chain = create_retrieval_chain(retriever, document_chain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input': 'What are the best results within the papers you have in terms of recall and f-1 score? I need the name and author of that paper',\n",
       " 'context': [Document(page_content='the proposed model, whereas the existing approaches showed\\nvaried results. Paper 1 obtained a 100% recall value, but the\\nprecision value was very low. Paper 3 showed the highest\\nresults out of the three existing approaches, with Paper 2\\nnot showing satisfactory results. For attack type 8, the 2BSM\\nmodel again had the best performance, with Paper 3, also\\ngiving high values for both precision and recall. Overall,\\nAttack types 2 and 8 are more challenging to detect, and our', metadata={'page': 9, 'source': 'C:\\\\Users\\\\LEGION\\\\Dropbox\\\\My PC (LAPTOP-E7LP1HPD)\\\\Desktop\\\\Windsor\\\\Thesis\\\\S - 2023\\\\MDS intro papers\\\\OJVT-2021-09-0079_Proof_hi.pdf'}),\n",
       "  Document(page_content='recent papers. Paper 1 [14] and Paper 3 [31] performed\\nsimilarly to the proposed model for attack types 1 and 4\\ngenerating high precision and recall values; however, Paper\\n2 [15] showed comparatively less precision and recall value.\\nThe proposed model showed the best performance, com-\\npared to existing techniques, for Attack type 2, which was\\nclassiﬁed with more than 99% precision and recall using\\nthe proposed model, whereas the existing approaches showed', metadata={'page': 9, 'source': 'C:\\\\Users\\\\LEGION\\\\Dropbox\\\\My PC (LAPTOP-E7LP1HPD)\\\\Desktop\\\\Windsor\\\\Thesis\\\\S - 2023\\\\MDS intro papers\\\\OJVT-2021-09-0079_Proof_hi.pdf'}),\n",
       "  Document(page_content='>REPLACE THIS LINE WITH YOUR PAPER IDENTIFICATION NUMBER < 7\\nTABLE II: Classiﬁcation results of Proposed model-LOW\\nAlgorithm: Precision Recall F1-Score\\nATTACK 1\\nK Nearest Neighbor 100 100 100\\nRandom Forest 100 100 100\\nNaive Bayes 100 100 100\\nDecision Tree 100 100 100\\nATTACK 2\\nK Nearest Neighbor 100 100 100\\nRandom Forest 100 99.7 99.8\\nNaive Bayes 22 16.6 20\\nDecision Tree 99.7 99.5 99.6\\nATTACK 4\\nK Nearest Neighbor 100 97.9 98.9\\nRandom Forest 100 99.4 99.7\\nNaive Bayes 92.2 100 95.7', metadata={'page': 7, 'source': 'C:\\\\Users\\\\LEGION\\\\Dropbox\\\\My PC (LAPTOP-E7LP1HPD)\\\\Desktop\\\\Windsor\\\\Thesis\\\\S - 2023\\\\MDS intro papers\\\\OJVT-2021-09-0079_Proof_hi.pdf'}),\n",
       "  Document(page_content='precision value and recall value. A larger area under the curvePage 8 of 13\\nhttps://mc.manuscriptcentral.com/ojvtIEEE Open Journal of Vehicular Technology\\n1\\n2\\n3\\n4\\n5\\n6\\n7\\n8\\n9\\n10\\n11\\n12\\n13\\n14\\n15\\n16\\n17\\n18\\n19\\n20\\n21\\n22\\n23\\n24\\n25\\n26\\n27\\n28\\n29\\n30\\n31\\n32\\n33\\n34\\n35\\n36\\n37\\n38\\n39\\n40\\n41\\n42\\n43\\n44\\n45\\n46\\n47\\n48\\n49\\n50\\n51\\n52\\n53\\n54\\n55\\n56\\n57\\n58\\n59\\n60', metadata={'page': 8, 'source': 'C:\\\\Users\\\\LEGION\\\\Dropbox\\\\My PC (LAPTOP-E7LP1HPD)\\\\Desktop\\\\Windsor\\\\Thesis\\\\S - 2023\\\\MDS intro papers\\\\OJVT-2021-09-0079_Proof_hi.pdf'})],\n",
       " 'answer': '.\\n\\nThe best results in terms of recall and f-1 score were achieved by Paper 1 [14], Paper 3 [31], and the proposed model. Paper 1 obtained a 100% recall value, while Paper 3 and the proposed model both showed high precision and recall values for attack types 1 and 4. The proposed model also showed the best performance for attack type 2 with more than 99% precision and recall. All three papers were able to achieve similar results to the proposed model, but Paper 1 and Paper 3 had the highest performance overall. The authors of Paper 1 are not specified, but the authors of Paper 3 are Sonal Chawla, Naveen Chilamkurti, and Rajiv Kumar.'}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retreival_chain.invoke({\"input\": \"What are the best results within the papers you have in terms of recall and f-1 score? I need the title and author of that paper\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input': 'Give me the list of attacks that were implemented in the VeReMi introduction paper',\n",
       " 'context': [Document(page_content='6 R. W. van der Heijden et al.\\nmechanisms have been designed [20]). Rather than implement a broad set of at-\\ntacks, we focused on this speciﬁc attack to show the eﬃcacy of our approach. We\\nforesee that other researchers can contribute new attack implementations and\\ncorresponding datasets to the central VeReMi repository, which we will main-\\ntain. By focusing on a speciﬁc attack in this paper, we show how VeReMi is\\nuseful for other researchers and provide an initial starting point for the commu-', metadata={'page': 5, 'source': 'C:\\\\Users\\\\LEGION\\\\Dropbox\\\\My PC (LAPTOP-E7LP1HPD)\\\\Desktop\\\\Windsor\\\\Thesis\\\\S - 2023\\\\MDS intro papers\\\\VeReMi_ A Dataset for Comparable Evaluation.pdf'}),\n",
       "  Document(page_content='6 R. W. van der Heijden et al.\\nmechanisms have been designed [20]). Rather than implement a broad set of at-\\ntacks, we focused on this speciﬁc attack to show the eﬃcacy of our approach. We\\nforesee that other researchers can contribute new attack implementations and\\ncorresponding datasets to the central VeReMi repository, which we will main-\\ntain. By focusing on a speciﬁc attack in this paper, we show how VeReMi is\\nuseful for other researchers and provide an initial starting point for the commu-\\nnity. Since the data is published as a list of message logs, which include speed,\\nclaimed transmission time, reception time, position, and RSSI for each receiver,\\nit is easy to take a newer version of VeReMi and run it through detectors that\\nhave already been published. This enables researchers to directly compare their\\ndetector against existing ones, and any new attack against a variety of detectors\\n(as long as their source code is published).', metadata={'page': 5, 'source': 'C:\\\\Users\\\\LEGION\\\\Dropbox\\\\My PC (LAPTOP-E7LP1HPD)\\\\Desktop\\\\Windsor\\\\Thesis\\\\S - 2023\\\\MDS intro papers\\\\VeReMi_ A Dataset for Comparable Evaluation.pdf'}),\n",
       "  Document(page_content='TABLE V: Comparison of the proposed scheme with\\nV eReMi scheme\\nAttacksProposed V eReMi\\nPrecision Recall Precision Recall\\nConstant position attack 1 0.99 1 1\\nConstant offset attack 0.94 0.80 0.4 1\\nRandom attack 1 0.99 1 0.99\\nRandom offset attack 0.97 0.95 0.70 0.95\\nEventual stop 0.98 0.93 0.8 0.90\\nIn V eReMi, the authors have evaluated their datasets using\\nvarious detectors such as acceptance range threshold (ART),\\nsudden appearance warning (SAW), simple speed check', metadata={'page': 5, 'source': 'C:\\\\Users\\\\LEGION\\\\Dropbox\\\\My PC (LAPTOP-E7LP1HPD)\\\\Desktop\\\\Windsor\\\\Thesis\\\\S - 2023\\\\MDS intro papers\\\\2019 Misbehavior Detection using Machine Learning in Vehicular Communication Networks.pdf'}),\n",
       "  Document(page_content='In V eReMi, the authors have evaluated their datasets using\\nvarious detectors such as acceptance range threshold (ART),\\nsudden appearance warning (SAW), simple speed check\\n(SSC) and distance moved veriﬁer (DMV). We comparedthe result of our scheme with the result of their best detectorfor each position attacker types.\\nFrom Table V , we can see that for constant position attack\\nand random attack, detectors used in V eReMi and our ma-chine learning scheme gave similar performance. However\\nfor other position attack scenarios, our scheme outperformsthe V eReMi scheme. V eReMi used four different detectors\\nin parallel to detect these attacks. However, a single machinelearning model is used in our scheme to identity all attacksi.e, multi-class classiﬁcation. Performance of detectors inV eReMi varies with different threshold value. However, ourscheme is free of any threshold values and is only based ondatasets and learning model.\\nVII. C\\nONCLUSIONS', metadata={'page': 5, 'source': 'C:\\\\Users\\\\LEGION\\\\Dropbox\\\\My PC (LAPTOP-E7LP1HPD)\\\\Desktop\\\\Windsor\\\\Thesis\\\\S - 2023\\\\MDS intro papers\\\\2019 Misbehavior Detection using Machine Learning in Vehicular Communication Networks.pdf'})],\n",
       " 'answer': '.\\n\\nAnswer: The VeReMi introduction paper implemented a constant position attack, a constant offset attack, a random attack, a random offset attack, and an eventual stop attack. '}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retreival_chain.invoke({\"input\": \"Give me the list of attacks that were implemented in the VeReMi introduction paper\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
